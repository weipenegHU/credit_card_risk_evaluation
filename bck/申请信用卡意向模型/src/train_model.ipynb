{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a988dfac-5e96-40a6-b663-3c449a68edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "import numpy as np\n",
    "from glob2 import glob\n",
    "import warnings\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"lightgbm\")\n",
    "\n",
    "import lightgbm as lgbm\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import pickle\n",
    "import re\n",
    "import gc\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5be94d32-bd37-4349-8884-478675b5a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(config.TRAIN_BINARY_FILE)\n",
    "valid = pd.read_pickle(config.DEV_BINARY_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d19e3ee7-5c89-4e83-8e02-1ba9b343e863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-14 17:52:00,618]\u001b[0m A new study created in memory with name: no-name-cd7560f7-3405-4554-ab10-4f0cd814f273\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 17:52:31,958]\u001b[0m Trial 0 finished with value: 0.7749954567713652 and parameters: {'num_iterations': 847, 'learning_rate': 0.2388572891279491, 'num_leaves': 147, 'neg_bagging_fraction': 0.048090749665005546, 'lambda_l1': 1.1062842754741027e-06, 'lambda_l2': 4.6630125594034854e-07, 'bagging_freq': 50, 'min_child_samples': 186, 'max_bin': 265, 'min_data_in_bin': 6, 'feature_fraction': 0.8899531006564518}. Best is trial 0 with value: 0.7749954567713652.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 17:52:55,687]\u001b[0m Trial 1 finished with value: 0.7652044573633094 and parameters: {'num_iterations': 731, 'learning_rate': 0.500133624132809, 'num_leaves': 69, 'neg_bagging_fraction': 0.026034634612764642, 'lambda_l1': 6.333851122462012e-07, 'lambda_l2': 0.877976475690294, 'bagging_freq': 12, 'min_child_samples': 10, 'max_bin': 247, 'min_data_in_bin': 13, 'feature_fraction': 0.9858410881395624}. Best is trial 0 with value: 0.7749954567713652.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 17:54:17,040]\u001b[0m Trial 2 finished with value: 0.7824380415904969 and parameters: {'num_iterations': 433, 'learning_rate': 0.007561527927323003, 'num_leaves': 300, 'neg_bagging_fraction': 0.08589325343712412, 'lambda_l1': 8.17378444852004e-06, 'lambda_l2': 0.0006853216782322677, 'bagging_freq': 24, 'min_child_samples': 7, 'max_bin': 265, 'min_data_in_bin': 21, 'feature_fraction': 0.9090504944807012}. Best is trial 2 with value: 0.7824380415904969.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 17:54:41,614]\u001b[0m Trial 3 finished with value: 0.7703692630940804 and parameters: {'num_iterations': 215, 'learning_rate': 0.2585454845700685, 'num_leaves': 372, 'neg_bagging_fraction': 0.03527838601767747, 'lambda_l1': 1.0634505351028707e-05, 'lambda_l2': 1.9873209504012213e-05, 'bagging_freq': 37, 'min_child_samples': 63, 'max_bin': 203, 'min_data_in_bin': 12, 'feature_fraction': 0.9919741741721192}. Best is trial 2 with value: 0.7824380415904969.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 17:56:50,680]\u001b[0m Trial 4 finished with value: 0.7807690783176726 and parameters: {'num_iterations': 825, 'learning_rate': 0.006044294234552656, 'num_leaves': 16, 'neg_bagging_fraction': 0.09715723531265238, 'lambda_l1': 0.02082919661275861, 'lambda_l2': 0.005999610831010201, 'bagging_freq': 10, 'min_child_samples': 118, 'max_bin': 232, 'min_data_in_bin': 22, 'feature_fraction': 0.9559393049642836}. Best is trial 2 with value: 0.7824380415904969.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 17:57:10,936]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 17:57:44,537]\u001b[0m Trial 6 finished with value: 0.7811003365238768 and parameters: {'num_iterations': 50, 'learning_rate': 0.08670289051765964, 'num_leaves': 215, 'neg_bagging_fraction': 0.0837518505824694, 'lambda_l1': 0.00044478777578490716, 'lambda_l2': 0.34686538163513864, 'bagging_freq': 15, 'min_child_samples': 17, 'max_bin': 255, 'min_data_in_bin': 15, 'feature_fraction': 0.8206358625892315}. Best is trial 2 with value: 0.7824380415904969.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 17:58:27,861]\u001b[0m Trial 7 finished with value: 0.7806104123517088 and parameters: {'num_iterations': 101, 'learning_rate': 0.005984523168015065, 'num_leaves': 392, 'neg_bagging_fraction': 0.04912848925210215, 'lambda_l1': 0.01958069656561158, 'lambda_l2': 2.6531057799008005e-08, 'bagging_freq': 28, 'min_child_samples': 67, 'max_bin': 210, 'min_data_in_bin': 8, 'feature_fraction': 0.8995362374797339}. Best is trial 2 with value: 0.7824380415904969.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 17:58:48,807]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-03-14 17:59:09,741]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 11.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 10\n",
      "Best trial:\n",
      "  Value: 0.7824380415904969\n",
      "  Params: \n",
      "    num_iterations: 433\n",
      "    learning_rate: 0.007561527927323003\n",
      "    num_leaves: 300\n",
      "    neg_bagging_fraction: 0.08589325343712412\n",
      "    lambda_l1: 8.17378444852004e-06\n",
      "    lambda_l2: 0.0006853216782322677\n",
      "    bagging_freq: 24\n",
      "    min_child_samples: 7\n",
      "    max_bin: 265\n",
      "    min_data_in_bin: 21\n",
      "    feature_fraction: 0.9090504944807012\n"
     ]
    }
   ],
   "source": [
    "# 调参\n",
    "def objective(trial):\n",
    "#     train_resample = resample(train, replace=False, n_samples=1000000, stratify=train['下单用户'])\n",
    "    train_x, train_y = train.drop(columns='下单用户'), train['下单用户']\n",
    "    valid_x, valid_y = valid.drop(columns='下单用户'), valid['下单用户']\n",
    "    dtrain = lgbm.Dataset(train_x, label=train_y)\n",
    "    dvalid = lgbm.Dataset(valid_x, label=valid_y)\n",
    "    \n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"num_iterations\":trial.suggest_int('num_iterations',50,2000,log=True),\n",
    "        \"learning_rate\":trial.suggest_float(\"learning_rate\",0.001,1,log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 10,400, log=True),\n",
    "#         \"min_data_in_leaf\":trial.suggest_int(\"min_data_in_leaf\", 20,30,step=2, log=False),\n",
    "        \"neg_bagging_fraction\":trial.suggest_float(\"neg_bagging_fraction\", 0.025, 0.1, log=True),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-9, 10, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-9, 10, log=True),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 10, 100, log=True),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 200, log=True),\n",
    "        \"max_bin\":trial.suggest_int(\"max_bin\",200,300,log=True),\n",
    "        \"min_data_in_bin\":trial.suggest_int(\"min_data_in_bin\",5,30,step=1),\n",
    "        \"feature_fraction\":trial.suggest_float(\"feature_fraction\",0.8,1,log=True),\n",
    "        'num_threads':20,\n",
    "        'pos_bagging_fraction':1,\n",
    "        'early_stopping_round':10,\n",
    "    }\n",
    "    \n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n",
    "    gbm = lgbm.train(\n",
    "        param, dtrain, valid_sets=[dvalid], verbose_eval=False, callbacks=[pruning_callback],\n",
    "        categorical_feature=['gender','new_customer','bank_processed','pos_merchant','cluster_n_3','line_key','是否需要贷款',\n",
    "                            '学历','是否拥有信用卡','有多少张信用卡','职业']\n",
    "    )\n",
    "\n",
    "    preds = gbm.predict(valid_x)\n",
    "    value = roc_auc_score(valid_y, preds)\n",
    "    return value\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\"\n",
    "    )\n",
    "    study.optimize(objective, n_trials=10)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "169e1808-561f-4d33-8f1b-732159f3d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df = study.trials_dataframe()\n",
    "complete_trial = study_df.query('state == \"COMPLETE\"').sort_values('value', ascending=False).reset_index()\n",
    "complete_trial.rename(columns={'params_bagging_freq':'bagging_freq', 'params_feature_fraction':'feature_fraction',\n",
    "                              'params_lambda_l1':'lambda_l1','params_lambda_l2':'lambda_l2','params_learning_rate':'learning_rate',\n",
    "                              'params_max_bin':'max_bin','params_min_child_samples':'min_child_samples', 'params_min_data_in_bin':'min_data_in_bin',\n",
    "                              'params_neg_bagging_fraction':'neg_bagging_fraction','params_num_iterations':'num_iterations','params_num_leaves':'num_leaves'},\n",
    "                    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "706dc2e4-97a9-412d-a8a0-d9069e84fc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>bagging_freq</th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>lambda_l1</th>\n",
       "      <th>lambda_l2</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_bin</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>min_data_in_bin</th>\n",
       "      <th>neg_bagging_fraction</th>\n",
       "      <th>num_iterations</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.782438</td>\n",
       "      <td>2023-03-14 17:52:55.688687</td>\n",
       "      <td>2023-03-14 17:54:17.039270</td>\n",
       "      <td>0 days 00:01:21.350583</td>\n",
       "      <td>24</td>\n",
       "      <td>0.909050</td>\n",
       "      <td>8.173784e-06</td>\n",
       "      <td>6.853217e-04</td>\n",
       "      <td>0.007562</td>\n",
       "      <td>265</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>0.085893</td>\n",
       "      <td>433</td>\n",
       "      <td>300</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.781100</td>\n",
       "      <td>2023-03-14 17:57:10.937064</td>\n",
       "      <td>2023-03-14 17:57:44.537093</td>\n",
       "      <td>0 days 00:00:33.600029</td>\n",
       "      <td>15</td>\n",
       "      <td>0.820636</td>\n",
       "      <td>4.447878e-04</td>\n",
       "      <td>3.468654e-01</td>\n",
       "      <td>0.086703</td>\n",
       "      <td>255</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>0.083752</td>\n",
       "      <td>50</td>\n",
       "      <td>215</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>2023-03-14 17:54:41.615252</td>\n",
       "      <td>2023-03-14 17:56:50.679351</td>\n",
       "      <td>0 days 00:02:09.064099</td>\n",
       "      <td>10</td>\n",
       "      <td>0.955939</td>\n",
       "      <td>2.082920e-02</td>\n",
       "      <td>5.999611e-03</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>232</td>\n",
       "      <td>118</td>\n",
       "      <td>22</td>\n",
       "      <td>0.097157</td>\n",
       "      <td>825</td>\n",
       "      <td>16</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.780610</td>\n",
       "      <td>2023-03-14 17:57:44.538479</td>\n",
       "      <td>2023-03-14 17:58:27.861360</td>\n",
       "      <td>0 days 00:00:43.322881</td>\n",
       "      <td>28</td>\n",
       "      <td>0.899536</td>\n",
       "      <td>1.958070e-02</td>\n",
       "      <td>2.653106e-08</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>210</td>\n",
       "      <td>67</td>\n",
       "      <td>8</td>\n",
       "      <td>0.049128</td>\n",
       "      <td>101</td>\n",
       "      <td>392</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.774995</td>\n",
       "      <td>2023-03-14 17:52:00.620059</td>\n",
       "      <td>2023-03-14 17:52:31.958403</td>\n",
       "      <td>0 days 00:00:31.338344</td>\n",
       "      <td>50</td>\n",
       "      <td>0.889953</td>\n",
       "      <td>1.106284e-06</td>\n",
       "      <td>4.663013e-07</td>\n",
       "      <td>0.238857</td>\n",
       "      <td>265</td>\n",
       "      <td>186</td>\n",
       "      <td>6</td>\n",
       "      <td>0.048091</td>\n",
       "      <td>847</td>\n",
       "      <td>147</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.770369</td>\n",
       "      <td>2023-03-14 17:54:17.040795</td>\n",
       "      <td>2023-03-14 17:54:41.613935</td>\n",
       "      <td>0 days 00:00:24.573140</td>\n",
       "      <td>37</td>\n",
       "      <td>0.991974</td>\n",
       "      <td>1.063451e-05</td>\n",
       "      <td>1.987321e-05</td>\n",
       "      <td>0.258545</td>\n",
       "      <td>203</td>\n",
       "      <td>63</td>\n",
       "      <td>12</td>\n",
       "      <td>0.035278</td>\n",
       "      <td>215</td>\n",
       "      <td>372</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.765204</td>\n",
       "      <td>2023-03-14 17:52:31.959571</td>\n",
       "      <td>2023-03-14 17:52:55.687388</td>\n",
       "      <td>0 days 00:00:23.727817</td>\n",
       "      <td>12</td>\n",
       "      <td>0.985841</td>\n",
       "      <td>6.333851e-07</td>\n",
       "      <td>8.779765e-01</td>\n",
       "      <td>0.500134</td>\n",
       "      <td>247</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0.026035</td>\n",
       "      <td>731</td>\n",
       "      <td>69</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  number     value             datetime_start  \\\n",
       "0      2       2  0.782438 2023-03-14 17:52:55.688687   \n",
       "1      6       6  0.781100 2023-03-14 17:57:10.937064   \n",
       "2      4       4  0.780769 2023-03-14 17:54:41.615252   \n",
       "3      7       7  0.780610 2023-03-14 17:57:44.538479   \n",
       "4      0       0  0.774995 2023-03-14 17:52:00.620059   \n",
       "5      3       3  0.770369 2023-03-14 17:54:17.040795   \n",
       "6      1       1  0.765204 2023-03-14 17:52:31.959571   \n",
       "\n",
       "           datetime_complete               duration  bagging_freq  \\\n",
       "0 2023-03-14 17:54:17.039270 0 days 00:01:21.350583            24   \n",
       "1 2023-03-14 17:57:44.537093 0 days 00:00:33.600029            15   \n",
       "2 2023-03-14 17:56:50.679351 0 days 00:02:09.064099            10   \n",
       "3 2023-03-14 17:58:27.861360 0 days 00:00:43.322881            28   \n",
       "4 2023-03-14 17:52:31.958403 0 days 00:00:31.338344            50   \n",
       "5 2023-03-14 17:54:41.613935 0 days 00:00:24.573140            37   \n",
       "6 2023-03-14 17:52:55.687388 0 days 00:00:23.727817            12   \n",
       "\n",
       "   feature_fraction     lambda_l1     lambda_l2  learning_rate  max_bin  \\\n",
       "0          0.909050  8.173784e-06  6.853217e-04       0.007562      265   \n",
       "1          0.820636  4.447878e-04  3.468654e-01       0.086703      255   \n",
       "2          0.955939  2.082920e-02  5.999611e-03       0.006044      232   \n",
       "3          0.899536  1.958070e-02  2.653106e-08       0.005985      210   \n",
       "4          0.889953  1.106284e-06  4.663013e-07       0.238857      265   \n",
       "5          0.991974  1.063451e-05  1.987321e-05       0.258545      203   \n",
       "6          0.985841  6.333851e-07  8.779765e-01       0.500134      247   \n",
       "\n",
       "   min_child_samples  min_data_in_bin  neg_bagging_fraction  num_iterations  \\\n",
       "0                  7               21              0.085893             433   \n",
       "1                 17               15              0.083752              50   \n",
       "2                118               22              0.097157             825   \n",
       "3                 67                8              0.049128             101   \n",
       "4                186                6              0.048091             847   \n",
       "5                 63               12              0.035278             215   \n",
       "6                 10               13              0.026035             731   \n",
       "\n",
       "   num_leaves     state  \n",
       "0         300  COMPLETE  \n",
       "1         215  COMPLETE  \n",
       "2          16  COMPLETE  \n",
       "3         392  COMPLETE  \n",
       "4         147  COMPLETE  \n",
       "5         372  COMPLETE  \n",
       "6          69  COMPLETE  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abe7a6c0-0490-4094-b6d0-2f5bb89bbdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 225426, number of negative: 8422633\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.594223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1377\n",
      "[LightGBM] [Info] Number of data points in the train set: 8648059, number of used features: 33\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.026067 -> initscore=-3.620686\n",
      "[LightGBM] [Info] Start training from score -3.620686\n",
      "auc score:  0.7825896598459836\n",
      "[LightGBM] [Info] Number of positive: 225426, number of negative: 8422633\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.563601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1383\n",
      "[LightGBM] [Info] Number of data points in the train set: 8648059, number of used features: 33\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.026067 -> initscore=-3.620686\n",
      "[LightGBM] [Info] Start training from score -3.620686\n",
      "auc score:  0.7814828893641237\n"
     ]
    }
   ],
   "source": [
    "def train_model(train, dev, param):\n",
    "    train_x, train_y = train.drop(columns='下单用户'), train['下单用户']\n",
    "    valid_x, valid_y = dev.drop(columns='下单用户'), dev['下单用户']\n",
    "    dtrain = lgbm.Dataset(train_x, label=train_y)\n",
    "    dvalid = lgbm.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "    gbm = lgbm.train(param, dtrain, valid_sets=[dvalid], verbose_eval=False)\n",
    "    \n",
    "    preds = gbm.predict(valid_x)\n",
    "    auc_score = roc_auc_score(valid_y, preds)\n",
    "    print(\"auc score: \", auc_score)\n",
    "    \n",
    "    predictions = dev.copy()\n",
    "    predictions['pred_score'] = preds\n",
    "    predictions['pred_labels'] = list(map(lambda x: 1 if x > 0.5 else 0, preds))\n",
    "    predictions = predictions[['下单用户','pred_score','pred_labels']]\n",
    "    return gbm, predictions\n",
    "\n",
    "# 使用前两个模型做ensemble\n",
    "gbms = []\n",
    "predictions = []\n",
    "for i in range(0,complete_trial.shape[0]):\n",
    "    if i > 1:\n",
    "        break\n",
    "    params = dict(complete_trial.iloc[i,6:-1])\n",
    "    params.update({\"objective\": \"binary\",\n",
    "             \"boosting_type\": \"gbdt\",\n",
    "             'metric':\"auc\",\n",
    "             'pos_bagging_fraction':1,\n",
    "            'early_stopping_round':10})\n",
    "    model, pred = train_model(train, valid, params)\n",
    "    pred['model'] = f\"gbm{i}\"\n",
    "    # pickle.dump(model, open(f\"{config.MODEL_GBM}/gbm%d.pkl\" % (i), \"wb\"))\n",
    "    pred['id'] = pred.index.tolist()\n",
    "    gbms.append(model)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a9e1b69-2dd2-4168-9f08-b37b3ea9fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.concat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d34e7f9-dc24-46ac-bd8f-891314cb7f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['percentile'] = predictions.groupby(['model'])['pred_score'].rank(pct=True, ascending=False)\n",
    "predictions['percentile'] = predictions['percentile'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cde27664-6f3b-4743-9fcf-42ca8e95a1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10%, precision 0.1003, recall 0.4751\n",
      "top 20%, precision 0.0686, recall 0.6357\n",
      "top 30%, precision 0.0532, recall 0.7311\n",
      "top 40%, precision 0.0440, recall 0.8007\n",
      "top 50%, precision 0.0378, recall 0.8543\n",
      "top 60%, precision 0.0333, recall 0.8986\n",
      "top 70%, precision 0.0299, recall 0.9351\n",
      "top 80%, precision 0.0273, recall 0.9660\n",
      "top 90%, precision 0.0250, recall 0.9877\n",
      "top 100%, precision 0.0232, recall 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 评估用ensemble投票的precision和recall\n",
    "percentile = list(range(0, 101, 10))\n",
    "for p in percentile:\n",
    "    if p == 0:\n",
    "        continue\n",
    "    over_threshold = predictions.query(f'percentile < {p}').drop_duplicates(['id'])\n",
    "    precision = over_threshold['下单用户'].sum() / over_threshold.shape[0]\n",
    "    recall = over_threshold['下单用户'].sum() / (predictions['下单用户'].sum() / 2)\n",
    "    print(f'top {p}%, precision {precision:.4f}, recall {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d056b-88dd-44db-8905-1633a4279f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
