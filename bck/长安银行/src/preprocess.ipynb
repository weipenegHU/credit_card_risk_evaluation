{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee12f92d-918b-43c7-963e-3f602b198392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import config\n",
    "from utils import peek\n",
    "import joblib\n",
    "import pickle\n",
    "import missingno as msno\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59943a6b-0f9e-4f0d-8ef2-d83669f0abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(config.DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bfb01f4-9434-4976-bcd1-20620d6f16f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = data[data.duplicated(['customer_phone', 'apply_date_key'])].customer_phone.unique()\n",
    "remove_duplicates = data[data.customer_phone.isin(duplicates)].query('order_status_key != 6')\n",
    "data = data[~data['customer_phone'].isin(duplicates)]\n",
    "data = pd.concat([data, remove_duplicates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ec7eb8-744e-480d-9cdd-ec281b61a467",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9973, 18)\n",
      "   model_risk_v7_stongyong_score  omriskscoregeneral  als_m12_id_nbank_orgnum  \\\n",
      "0                           66.0               515.0                      7.0   \n",
      "1                           20.0               684.0                      2.0   \n",
      "\n",
      "   als_m12_id_nbank_min_inteday  als_m12_id_min_inteday  \\\n",
      "0                           0.0                     0.0   \n",
      "1                          60.0                    25.0   \n",
      "\n",
      "   als_m3_id_nbank_min_inteday  debt_pressure_index  v6_seq_online  \\\n",
      "0                          0.0                 31.0           38.0   \n",
      "1                      -9999.0                 17.0           36.0   \n",
      "\n",
      "   als_m12_id_nbank_week_orgnum  als_lst_id_nbank_consnum  \\\n",
      "0                           3.0                       1.0   \n",
      "1                           0.0                       1.0   \n",
      "\n",
      "   als_d15_id_nbank_orgnum  als_m1_id_nbank_week_orgnum in_black_list  \\\n",
      "0                      0.0                      -9999.0          True   \n",
      "1                      0.0                      -9999.0           NaN   \n",
      "\n",
      "   actual_age  gender degree card_num  order_status_key  \n",
      "0        27.0    male   大学专科       1张                 3  \n",
      "1        38.0  female   大学本科       3张                 2  \n"
     ]
    }
   ],
   "source": [
    "use_features = joblib.load(config.USE_FEATURES)\n",
    "label = ['order_status_key']\n",
    "use_cols = use_features + label\n",
    "data = data[use_cols]\n",
    "peek(data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b3511a-ccee-48d2-be29-0de07258085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['order_status_key'] = data['order_status_key'].map({2:1}).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49b14ae6-25fb-4948-bfb7-1ab72d3bd33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6236, 17)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.query('als_m12_id_nbank_orgnum < 9')\n",
    "data = data[pd.isnull(data['in_black_list'])].drop('in_black_list', axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ff4491-1a02-48e3-b472-a820490765a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['als_m12_id_nbank_orgnum', 'model_risk_v7_stongyong_score', 'v6_seq_online', 'omriskscoregeneral'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56c5cfde-ccfe-4aa1-8a5c-ed642204b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_map = {'male':0, 'female':1}\n",
    "data['gender'] = data['gender'].map(gender_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c260d52-c64a-44ec-b555-f1c809764dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['degree'] = data['degree'].fillna(\"NONE\")\n",
    "degree_map = {'高中及以下':1, '大学专科':2, '大学本科':3, '硕士（含）及以上':4, 'NONE':5}\n",
    "data['degree'] = data['degree'].map(degree_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e400bbe-324c-4ed5-a252-e5fbe909a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['card_num'] = data['card_num'].fillna(\"NONE\")\n",
    "card_num_map = {'无信用卡':0, '1张':1, '2张':2, '3张':3, '4张及以上':4, 'NONE':5}\n",
    "data['card_num'] = data['card_num'].map(card_num_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c91f6aba-63a8-4309-9261-89b8d87df147",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.3, random_state=42, stratify=data['order_status_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2edf967c-64dc-4a65-8dcc-b98fb7b18608",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a70ee549-ecc4-46f4-877d-811bd73ec21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    870\n",
       "1.0    870\n",
       "3.0    870\n",
       "2.0    870\n",
       "4.0    869\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = -1\n",
    "splitter = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for f, (t, v) in enumerate(splitter.split(train, train['order_status_key'])):\n",
    "    train.loc[v, 'fold'] = f\n",
    "train['fold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3e6443e-9be4-4507-b373-ffb9ea962da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Binner:\n",
    "    def __init__(self):\n",
    "        self.feature_bins = {}\n",
    "\n",
    "    def fit(self, df):\n",
    "        features = df.columns\n",
    "        percentiles = list(range(0, 101, 10))\n",
    "\n",
    "        for f in features:\n",
    "            val = np.percentile(df[[f]], percentiles).tolist()\n",
    "            if min(val) >= 0:\n",
    "                bins = list(sorted(set([-999999, 999999] + val)))\n",
    "            else:\n",
    "                bins = list(sorted(set([-999999, 999999] + [-10000, -9999] + val)))\n",
    "            self.feature_bins[f] = bins\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        if not self.feature_bins:\n",
    "            print(\"Error: Binner is not fitted yet\")\n",
    "            return\n",
    "        else:\n",
    "            df_bin = df.copy()\n",
    "            for f in df_bin.columns:\n",
    "                bins = self.feature_bins[f]\n",
    "                df_bin[f] = pd.cut(df_bin[f], bins, labels= list(range(len(bins) - 1))).astype(\"int\")\n",
    "            return df_bin\n",
    "        \n",
    "        \n",
    "def preprocess1(data, is_train=True):\n",
    "    processed = data.copy()\n",
    "    binning_features = ['als_m12_id_nbank_orgnum', 'als_m12_id_nbank_min_inteday',\n",
    "                       'als_m12_id_min_inteday', 'als_m3_id_nbank_min_inteday',\n",
    "                        'als_m12_id_nbank_week_orgnum','als_lst_id_nbank_consnum', \n",
    "                        'als_d15_id_nbank_orgnum','als_m1_id_nbank_week_orgnum']\n",
    "    scale_features = ['model_risk_v7_stongyong_score', 'omriskscoregeneral', 'debt_pressure_index', 'v6_seq_online', \n",
    "                      'actual_age']\n",
    "    cat_features = ['gender', 'degree', 'card_num']\n",
    "    processed[binning_features]\n",
    "    if is_train:\n",
    "        binner = Binner()\n",
    "        binner.fit(processed[binning_features])\n",
    "        processed[binning_features] = binner.transform(processed[binning_features])\n",
    "        pickle.dump(binner, open(config.BINNER, 'wb'))\n",
    "        scaler = StandardScaler()\n",
    "        processed[scale_features] = scaler.fit_transform(processed[scale_features])\n",
    "        pickle.dump(scaler, open(config.SCALER, \"wb\"))\n",
    "        onehot_enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        encoded = pd.DataFrame(onehot_enc.fit_transform(processed.loc[:, cat_features]).toarray(), columns=onehot_enc.get_feature_names_out(cat_features))\n",
    "        pickle.dump(onehot_enc, open(config.ENCODER, 'wb'))\n",
    "    else:\n",
    "        try:\n",
    "            scaler = joblib.load(config.SCALER)\n",
    "            encoder = joblib.load(config.ENCODER)\n",
    "            binner = joblib.load(config.BINNER)\n",
    "        except FileNotFoundError:\n",
    "            print(\"Error: scaler, encoder or binner does not exist\")\n",
    "            return\n",
    "            \n",
    "        processed[binning_features] = binner.transform(processed[binning_features])\n",
    "        processed[scale_features] = scaler.transform(processed[scale_features])\n",
    "        encoded = pd.DataFrame(encoder.transform(processed[cat_features]).toarray(), columns=encoder.get_feature_names_out(cat_features))\n",
    "    \n",
    "    processed = processed.drop(columns=cat_features)\n",
    "    processed = pd.concat([encoded, processed], axis=1)\n",
    "    return processed\n",
    "\n",
    "\n",
    "def preprocess2(data, is_train=True):\n",
    "    processed = data.copy()\n",
    "    cat_features = ['gender', 'degree', 'card_num']\n",
    "    if is_train:\n",
    "        onehot_enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        encoded = pd.DataFrame(onehot_enc.fit_transform(processed.loc[:, cat_features]).toarray(), columns=onehot_enc.get_feature_names_out(cat_features))\n",
    "        pickle.dump(onehot_enc, open(config.ENCODER, 'wb'))\n",
    "    else:\n",
    "        try:\n",
    "            encoder = joblib.load(config.ENCODER)\n",
    "        except FileNotFoundError:\n",
    "            print(\"Error: scaler, encoder or binner does not exist\")\n",
    "            return\n",
    "            \n",
    "        encoded = pd.DataFrame(encoder.transform(processed[cat_features]).toarray(), columns=encoder.get_feature_names_out(cat_features))\n",
    "    \n",
    "    processed = processed.drop(columns=cat_features)\n",
    "    processed = pd.concat([encoded, processed], axis=1)\n",
    "    return processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56e20eba-29d5-4d76-b82f-f602c30f9fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed = preprocess2(train)\n",
    "test_processed = preprocess2(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6104410c-074f-4b54-9698-5402e5ce580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_processed.to_csv(config.TRAIN, index=False)\n",
    "# test_processed.to_csv(config.TEST, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6400bef-a407-4461-a4f2-cae73e9f05e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_processed.to_csv(config.TRAIN2, index=False)\n",
    "test_processed.to_csv(config.TEST2, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1e538b9-045d-4195-b496-f76237f3d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(config.TRAIN3, index=False)\n",
    "test.to_csv(config.TEST3, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa1d1d-b8e3-402c-971e-34835bbf2a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afb1675-194b-4dda-b633-7bd8fe1a191b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b06af07-69df-4067-acdc-a8f412cb2618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b030d-c364-445e-95cd-add8c90c1874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
